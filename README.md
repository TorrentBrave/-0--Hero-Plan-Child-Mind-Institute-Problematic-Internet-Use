# [CMI | Features EDA](https://www.kaggle.com/code/antoninadolgorukova/cmi-piu-features-eda)

# [CMI | EDA which makes sense](https://www.kaggle.com/code/ambrosm/piu-eda-which-makes-sense#A-look-at-selected-other-features)

* a first analysis of the data

* how to ___cross-validate___ a model

* that ___regression___ models are better than ___classification___ models in this competition, and

* how to ___tune the thresholds for rounding the regression output___.

* The notebook uses ___polars___ DataFrames. If you are more fluent with pandas than with polars, this is an opportunity to get to know polars, which is often more ___efficient than pandas___.

# [CMI | Best Single Model](https://www.kaggle.com/code/abdmental01/cmi-best-single-model)

# [CMI | 1st Place Solution](https://www.kaggle.com/code/lennarthaupts/1st-place-cmi-model-v4-1-1-reduced/notebook?scriptVersionId=213769368)

voted ensemble consisting of:
(improving the robustness)

* __LGBMRegressor__

* __Two__[__XGBoost__](https://www.kaggle.com/code/prashant111/a-guide-on-xgboost-hyperparameters-tuning)__Regressors__

* __CatBoostRegressor__ 

* __ExtraTreesRegressor__
